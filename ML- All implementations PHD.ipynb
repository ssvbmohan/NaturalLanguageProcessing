{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Import Libraries \n",
    "import numpy as np      # for array operations\n",
    "import pandas as pd     # for reading data operations\n",
    "\n",
    "from keras.preprocessing.text import Tokenizer          # for tokenizing text\n",
    "from keras.preprocessing.sequence import pad_sequences  # for padding sentences with zeros. To make the sentence length same\n",
    "from keras.utils import to_categorical                  # for one-hot encoding of the labels\n",
    "from keras.layers import Dense, Input, Flatten, Dropout, BatchNormalization\n",
    "from keras.layers import SimpleRNN, LSTM, GRU, Input, Concatenate\n",
    "from keras.layers import Conv1D, MaxPooling1D, GlobalMaxPool1D, Embedding, GlobalAvgPool1D\n",
    "from keras.models import Sequential, Model\n",
    "import os\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"1\"\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.classify.scikitlearn import SklearnClassifier\n",
    "from nltk.tokenize import sent_tokenize,word_tokenize\n",
    "from nltk.collocations import BigramCollocationFinder \n",
    "from wordcloud import WordCloud\n",
    "\n",
    "import spacy\n",
    "nlp = spacy.load('en_core_web_sm')\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import f1_score\n",
    "\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "pd.set_option('display.max_colwidth',-1)\n",
    "\n",
    "import urllib.request as url\n",
    "from bs4 import BeautifulSoup as bs\n",
    "import re\n",
    "import requests\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import random\n",
    "random.seed(123)\n",
    "\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "\n",
    "import os\n",
    "import random\n",
    "import string\n",
    "import datetime as dt\n",
    "\n",
    "# import warnings\n",
    "# warnings.filterwarnings('ignore','RuntimeWarning')\n",
    "\n",
    "import nltk\n",
    "import re\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.classify.scikitlearn import SklearnClassifier\n",
    "from nltk.tokenize import sent_tokenize, word_tokenize\n",
    "from nltk.collocations import BigramCollocationFinder, TrigramCollocationFinder\n",
    "from wordcloud import WordCloud\n",
    "\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from nltk.corpus import movie_reviews\n",
    "from nltk.classify.scikitlearn import SklearnClassifier\n",
    "from nltk.tokenize import word_tokenize\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.metrics import confusion_matrix,accuracy_score,recall_score,precision_score\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "from sklearn.model_selection import train_test_split\n",
    "import nltk\n",
    "\n",
    "from sklearn.metrics import f1_score\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "filename = 'f1.csv'\n",
    "infile = open(filename,'rb')\n",
    "train_text_dt = pickle.load(infile)\n",
    "infile.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3000, 26)"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_text_dt.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['review', 'displayImageUrl', 'isVerified', 'isSuperReviewer',\n",
       "       'hasSpoilers', 'hasProfanity', 'createDate', 'updateDate', 'score',\n",
       "       'timeFromCreation', 'user.realm', 'user.displayName', 'sentiment',\n",
       "       'Create_day', 'create_time', 'update_day', 'update_time',\n",
       "       'review_update_date', 'review_processed_1', 'review_processed_2',\n",
       "       'review_processed_3', 'polarity', 'review_len', 'word_count',\n",
       "       'review_len_cat', 'word_count_cat'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_text_dt.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_text_dt = train_text_dt.drop(labels=['displayImageUrl', 'isVerified', 'isSuperReviewer',\n",
    "       'hasSpoilers', 'hasProfanity', 'createDate', 'updateDate', 'score',\n",
    "       'timeFromCreation', 'user.realm', 'user.displayName',\n",
    "       'Create_day', 'create_time', 'update_day', 'update_time',\n",
    "       'review_update_date'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review</th>\n",
       "      <th>sentiment</th>\n",
       "      <th>review_processed_1</th>\n",
       "      <th>review_processed_2</th>\n",
       "      <th>review_processed_3</th>\n",
       "      <th>polarity</th>\n",
       "      <th>review_len</th>\n",
       "      <th>word_count</th>\n",
       "      <th>review_len_cat</th>\n",
       "      <th>word_count_cat</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>559</th>\n",
       "      <td>The movie missed a lot of lines from the cartoon version</td>\n",
       "      <td>0</td>\n",
       "      <td>[movie, missed, line, cartoon, version]</td>\n",
       "      <td>[movie, missed, line, cartoon, version]</td>\n",
       "      <td>The movie missed a lot of lines from the cartoon version</td>\n",
       "      <td>0.0</td>\n",
       "      <td>56</td>\n",
       "      <td>11</td>\n",
       "      <td>lessthan150</td>\n",
       "      <td>10-30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1888</th>\n",
       "      <td>The Lion King was a great family movie absolutely loved it!!!</td>\n",
       "      <td>1</td>\n",
       "      <td>[lion, king, great, family, movie, absolutely, loved, it!!!]</td>\n",
       "      <td>[Lion, King, great, family, movie, absolutely, loved]</td>\n",
       "      <td>The Lion King was a great family movie absolutely loved it!!!</td>\n",
       "      <td>0.9</td>\n",
       "      <td>61</td>\n",
       "      <td>11</td>\n",
       "      <td>lessthan150</td>\n",
       "      <td>10-30</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                             review  \\\n",
       "559   The movie missed a lot of lines from the cartoon version        \n",
       "1888  The Lion King was a great family movie absolutely loved it!!!   \n",
       "\n",
       "      sentiment                                            review_processed_1  \\\n",
       "559   0          [movie, missed, line, cartoon, version]                        \n",
       "1888  1          [lion, king, great, family, movie, absolutely, loved, it!!!]   \n",
       "\n",
       "                                         review_processed_2  \\\n",
       "559   [movie, missed, line, cartoon, version]                 \n",
       "1888  [Lion, King, great, family, movie, absolutely, loved]   \n",
       "\n",
       "                                                 review_processed_3  polarity  \\\n",
       "559   The movie missed a lot of lines from the cartoon version       0.0        \n",
       "1888  The Lion King was a great family movie absolutely loved it!!!  0.9        \n",
       "\n",
       "      review_len  word_count review_len_cat word_count_cat  \n",
       "559   56          11          lessthan150    10-30          \n",
       "1888  61          11          lessthan150    10-30          "
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_text_dt.sample(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_text_dt['review_processed_2'] = train_text_dt[\"review_processed_2\"].apply(lambda x:' '.join(x))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_text_dt['review_processed_1'] = train_text_dt['review_processed_1'].apply(lambda x:' '.join(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_text_dt['sentiment'] = train_text_dt['sentiment'].replace({0:1, 1:0})\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Review_processed_1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### count vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train_r1, X_test_r1, y_train_r1, y_test_r1 = train_test_split(train_text_dt['review_processed_1'],train_text_dt['sentiment'],test_size=0.25,random_state=123)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2250\n",
      "750\n"
     ]
    }
   ],
   "source": [
    "print(len(X_train_r1))\n",
    "print(len(X_test_r1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "cv = CountVectorizer(stop_words=\"english\",strip_accents=\"unicode\",decode_error=\"ignore\")\n",
    "tdm_train_r1 = cv.fit_transform(X_train_r1)\n",
    "tdm_test_r1 = cv.transform(X_test_r1)\n",
    "\n",
    "##########################################################################################\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "tfidf_vectorizer = TfidfVectorizer(ngram_range=(1,2))\n",
    "tfidf_train_r1 = tfidf_vectorizer.fit_transform(X_train_r1)\n",
    "tfidf_test_r1 = tfidf_vectorizer.transform(X_test_r1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "#training the model\n",
    "logreg = LogisticRegression()\n",
    "lr_clf = logreg.fit(tdm_train_r1,y_train_r1) #or mat which is in dense format can also be used\n",
    "\n",
    "#prediction on train data\n",
    "train_pred_r1 = lr_clf.predict(tdm_train_r1)\n",
    "\n",
    "#predicting on test data\n",
    "test_pred_r1 = lr_clf.predict(tdm_test_r1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train cfm : \n",
      " [[1602   24]\n",
      " [ 113  511]]\n",
      "train cfm : \n",
      " [[521  30]\n",
      " [ 92 107]]\n"
     ]
    }
   ],
   "source": [
    "print(\"train cfm :\",\"\\n\", confusion_matrix(y_train_r1,train_pred_r1))\n",
    "print(\"train cfm :\",\"\\n\", confusion_matrix(y_test_r1,test_pred_r1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8817946505608283\n",
      "0.636904761904762\n"
     ]
    }
   ],
   "source": [
    "f1_train_r1_log=f1_score( y_train_r1, train_pred_r1, labels=None, pos_label=1, average='binary')\n",
    "f1_test_r1_log=f1_score( y_test_r1, test_pred_r1, labels=None, pos_label=1, average='binary')\n",
    "print(f1_train_r1_log)\n",
    "print(f1_test_r1_log)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### tfidf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train_r1, X_test_r1, y_train_r1, y_test_r1 = train_test_split(train_text_dt['review_processed_1'],train_text_dt['sentiment'],test_size=0.25,random_state=123)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2250\n",
      "750\n"
     ]
    }
   ],
   "source": [
    "print(len(X_train_r1))\n",
    "print(len(X_test_r1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "cv = CountVectorizer(stop_words=\"english\",strip_accents=\"unicode\",decode_error=\"ignore\")\n",
    "tdm_train_r1 = cv.fit_transform(X_train_r1)\n",
    "tdm_test_r1 = cv.transform(X_test_r1)\n",
    "\n",
    "##########################################################################################\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "tfidf_vectorizer = TfidfVectorizer(ngram_range=(1,2))\n",
    "tfidf_train_r1 = tfidf_vectorizer.fit_transform(X_train_r1)\n",
    "tfidf_test_r1 = tfidf_vectorizer.transform(X_test_r1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "#training the model\n",
    "logreg = LogisticRegression()\n",
    "lr_clf = logreg.fit(tfidf_train_r1,y_train_r1) #or mat which is in dense format can also be used\n",
    "\n",
    "#prediction on train data\n",
    "train_pred_r1 = lr_clf.predict(tfidf_train_r1)\n",
    "\n",
    "#predicting on test data\n",
    "test_pred_r1 = lr_clf.predict(tfidf_test_r1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train cfm : \n",
      " [[1621    5]\n",
      " [ 277  347]]\n",
      "train cfm : \n",
      " [[540  11]\n",
      " [132  67]]\n"
     ]
    }
   ],
   "source": [
    "print(\"train cfm :\",\"\\n\", confusion_matrix(y_train_r1,train_pred_r1))\n",
    "print(\"train cfm :\",\"\\n\", confusion_matrix(y_test_r1,test_pred_r1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7110655737704918\n",
      "0.4837545126353791\n"
     ]
    }
   ],
   "source": [
    "f1_train_r1_log=f1_score( y_train_r1, train_pred_r1, labels=None, pos_label=1, average='binary')\n",
    "f1_test_r1_log=f1_score( y_test_r1, test_pred_r1, labels=None, pos_label=1, average='binary')\n",
    "print(f1_train_r1_log)\n",
    "print(f1_test_r1_log)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### random forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [],
   "source": [
    "#build a random forest classifiers\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "rf = RandomForestClassifier()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_clf = rf.fit(tdm_train_r1,y_train_r1)\n",
    "#prediction on train data\n",
    "train_pred_r1 = rf_clf.predict(tdm_train_r1)\n",
    "\n",
    "#predicting on test data\n",
    "test_predr1 = rf_clf.predict(tdm_test_r1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.955\n",
      "0.4837545126353791\n"
     ]
    }
   ],
   "source": [
    "f1_train_r1_rf=f1_score( y_train_r1, train_pred_r1, labels=None, pos_label=1, average='binary')\n",
    "f1_test_r1_rf=f1_score( y_test_r1, test_pred_r1, labels=None, pos_label=1, average='binary')\n",
    "print(f1_train_r1_rf)\n",
    "print(f1_test_r1_rf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### svm/cv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SVC(C=1.0, cache_size=200, class_weight=None, coef0=0.0,\n",
       "    decision_function_shape='ovr', degree=3, gamma='auto_deprecated',\n",
       "    kernel='rbf', max_iter=-1, probability=False, random_state=None,\n",
       "    shrinking=True, tol=0.001, verbose=False)"
      ]
     },
     "execution_count": 207,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Build a SVM Classifier\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "## Create an SVC object and print it to see the default arguments\n",
    "svc = SVC()\n",
    "svc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SVC(C=10, cache_size=200, class_weight=None, coef0=0.0,\n",
       "    decision_function_shape='ovr', degree=3, gamma='auto_deprecated',\n",
       "    kernel='rbf', max_iter=-1, probability=False, random_state=None,\n",
       "    shrinking=True, tol=0.001, verbose=False)"
      ]
     },
     "execution_count": 208,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "svc_c10_rbf = SVC(C=10,kernel='rbf')\n",
    "svc_c10_rbf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Fit the model svc_c10_rbf on the train data (X_train,y_train)\n",
    "svc_c10_rbf.fit(X = tdm_train_r1,y = y_train_r1)\n",
    "\n",
    "#prediction on train data\n",
    "train_pred_r1 = svc_c10_rbf.predict(tdm_train_r1)\n",
    "\n",
    "#predicting on test data\n",
    "test_pred_r1 = svc_c10_rbf.predict(tdm_test_r1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.18497109826589592\n",
      "0.13761467889908255\n"
     ]
    }
   ],
   "source": [
    "f1_train_r1_svc=f1_score( y_train_r1, train_pred_r1, labels=None, pos_label=1, average='binary')\n",
    "f1_test_r1_svc=f1_score( y_test_r1, test_pred_r1, labels=None, pos_label=1, average='binary')\n",
    "print(f1_train_r1_svc)\n",
    "print(f1_test_r1_svc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Grid search on svc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Use Grid Search for parameter tuning\n",
    "\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "svc_grid = SVC()\n",
    " \n",
    "\n",
    "param_grid = {\n",
    "\n",
    "'C': [0.001, 0.01, 0.1, 1, 10],\n",
    "'gamma': [0.001, 0.01, 0.1, 1], \n",
    "'kernel':['linear', 'poly', 'rbf', 'sigmoid']}\n",
    "\n",
    " \n",
    "svc_cv_grid = GridSearchCV(estimator = svc_grid, param_grid = param_grid, cv = 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Fit the grid search model\n",
    "svc_cv_grid.fit(X = tdm_train_r1, y = y_train_r1)\n",
    "\n",
    "train_pred_r1 = svc_cv_grid.predict(tdm_train_r1)\n",
    "\n",
    "test_pred_r1 = svc_cv_grid.predict(tdm_test_r1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8093333333333333 {'C': 10, 'gamma': 0.01, 'kernel': 'rbf'}\n"
     ]
    }
   ],
   "source": [
    "## Print best score and parameters\n",
    "print(svc_cv_grid.best_score_,svc_cv_grid.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "metadata": {},
   "outputs": [],
   "source": [
    "svc_clf_grid = SVC(C=10, gamma=0.01, kernel= 'rbf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8653500897666068\n",
      "0.6257668711656441\n"
     ]
    }
   ],
   "source": [
    "f1_train_r1_svc=f1_score( y_train_r1, train_pred_r1, labels=None, pos_label=1, average='binary')\n",
    "f1_test_r1_svc=f1_score( y_test_r1, test_pred_r1, labels=None, pos_label=1, average='binary')\n",
    "print(f1_train_r1_svc)\n",
    "print(f1_test_r1_svc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Fit the grid search model\n",
    "svc_cv_grid.fit(X = tfidf_train_r1, y = y_train_r1)\n",
    "\n",
    "train_pred_r1_tf = svc_cv_grid.predict(tfidf_train_r1)\n",
    "\n",
    "test_pred_r1_tf = svc_cv_grid.predict(tfidf_test_r1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8653500897666068\n",
      "0.6257668711656441\n"
     ]
    }
   ],
   "source": [
    "f1_train_r1_svc=f1_score( y_train_r1, train_pred_r1, labels=None, pos_label=1, average='binary')\n",
    "f1_test_r1_svc=f1_score( y_test_r1, test_pred_r1, labels=None, pos_label=1, average='binary')\n",
    "print(f1_train_r1_svc)\n",
    "print(f1_test_r1_svc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8257777777777778 {'C': 10, 'gamma': 0.1, 'kernel': 'rbf'}\n"
     ]
    }
   ],
   "source": [
    "## Print best score and parameters\n",
    "print(svc_cv_grid.best_score_,svc_cv_grid.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "metadata": {},
   "outputs": [],
   "source": [
    "svc_clf_grid = SVC(C=10, gamma=0.1, kernel= 'rbf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8653500897666068\n",
      "0.6257668711656441\n"
     ]
    }
   ],
   "source": [
    "f1_train_r1_svc=f1_score( y_train_r1, train_pred_r1, labels=None, pos_label=1, average='binary')\n",
    "f1_test_r1_svc=f1_score( y_test_r1, test_pred_r1, labels=None, pos_label=1, average='binary')\n",
    "print(f1_train_r1_svc)\n",
    "print(f1_test_r1_svc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### review processed 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train_r2, X_test_r2, y_train_r2, y_test_r2 = train_test_split(train_text_dt['review_processed_2'],train_text_dt['sentiment'],test_size=0.25,random_state=123)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2250\n",
      "750\n"
     ]
    }
   ],
   "source": [
    "print(len(X_train_r2))\n",
    "print(len(X_test_r2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "cv = CountVectorizer(stop_words=\"english\",strip_accents=\"unicode\",decode_error=\"ignore\")\n",
    "tdm_train_r2 = cv.fit_transform(X_train_r2)\n",
    "tdm_test_r2 = cv.transform(X_test_r2)\n",
    "\n",
    "##########################################################################################\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "tfidf_vectorizer = TfidfVectorizer(ngram_range=(1,2))\n",
    "tfidf_train_r2 = tfidf_vectorizer.fit_transform(X_train_r2)\n",
    "tfidf_test_r2 = tfidf_vectorizer.transform(X_test_r2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "#training the model\n",
    "logreg = LogisticRegression()\n",
    "lr_clf = logreg.fit(tdm_train_r2,y_train_r2) #or mat which is in dense format can also be used\n",
    "\n",
    "#prediction on train data\n",
    "train_pred_r2 = lr_clf.predict(tdm_train_r2)\n",
    "\n",
    "#predicting on test data\n",
    "test_pred_r2 = lr_clf.predict(tdm_test_r2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train cfm : \n",
      " [[1599   27]\n",
      " [ 123  501]]\n",
      "train cfm : \n",
      " [[524  27]\n",
      " [ 93 106]]\n"
     ]
    }
   ],
   "source": [
    "print(\"train cfm :\",\"\\n\", confusion_matrix(y_train_r2,train_pred_r2))\n",
    "print(\"train cfm :\",\"\\n\", confusion_matrix(y_test_r2,test_pred_r2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8697916666666667\n",
      "0.6385542168674698\n"
     ]
    }
   ],
   "source": [
    "f1_train_r2_log=f1_score( y_train_r2, train_pred_r2, labels=None, pos_label=1, average='binary')\n",
    "f1_test_r2_log=f1_score( y_test_r2, test_pred_r2, labels=None, pos_label=1, average='binary')\n",
    "print(f1_train_r2_log)\n",
    "print(f1_test_r2_log)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### tfidf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train_r2, X_test_r2, y_train_r2, y_test_r2 = train_test_split(train_text_dt['review_processed_2'],train_text_dt['sentiment'],test_size=0.25,random_state=123)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2250\n",
      "750\n"
     ]
    }
   ],
   "source": [
    "print(len(X_train_r2))\n",
    "print(len(X_test_r2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "cv = CountVectorizer(stop_words=\"english\",strip_accents=\"unicode\",decode_error=\"ignore\")\n",
    "tdm_train_r2 = cv.fit_transform(X_train_r2)\n",
    "tdm_test_r2 = cv.transform(X_test_r2)\n",
    "\n",
    "##########################################################################################\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "tfidf_vectorizer = TfidfVectorizer(ngram_range=(1,2))\n",
    "tfidf_train_r2 = tfidf_vectorizer.fit_transform(X_train_r2)\n",
    "tfidf_test_r2 = tfidf_vectorizer.transform(X_test_r2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "#training the model\n",
    "logreg = LogisticRegression()\n",
    "lr_clf = logreg.fit(tfidf_train_r2,y_train_r2) #or mat which is in dense format can also be used\n",
    "\n",
    "#prediction on train data\n",
    "train_pred_r2 = lr_clf.predict(tfidf_train_r2)\n",
    "\n",
    "#predicting on test data\n",
    "test_pred_r2 = lr_clf.predict(tfidf_test_r2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train cfm : \n",
      " [[1620    6]\n",
      " [ 273  351]]\n",
      "train cfm : \n",
      " [[540  11]\n",
      " [132  67]]\n"
     ]
    }
   ],
   "source": [
    "print(\"train cfm :\",\"\\n\", confusion_matrix(y_train_r2,train_pred_r2))\n",
    "print(\"train cfm :\",\"\\n\", confusion_matrix(y_test_r2,test_pred_r2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7155963302752292\n",
      "0.4837545126353791\n"
     ]
    }
   ],
   "source": [
    "f1_train_r2_log=f1_score( y_train_r2, train_pred_r2, labels=None, pos_label=1, average='binary')\n",
    "f1_test_r2_log=f1_score( y_test_r2, test_pred_r2, labels=None, pos_label=1, average='binary')\n",
    "print(f1_train_r2_log)\n",
    "print(f1_test_r2_log)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### random forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [],
   "source": [
    "#build a random forest classifiers\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "rf = RandomForestClassifier()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_clf = rf.fit(tdm_train_r2,y_train_r2)\n",
    "#prediction on train data\n",
    "train_pred_r2 = rf_clf.predict(tdm_train_r2)\n",
    "\n",
    "#predicting on test data\n",
    "test_predr2 = rf_clf.predict(tdm_test_r2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9429530201342282\n",
      "0.4837545126353791\n"
     ]
    }
   ],
   "source": [
    "f1_train_r2_rf=f1_score( y_train_r2, train_pred_r2, labels=None, pos_label=1, average='binary')\n",
    "f1_test_r2_rf=f1_score( y_test_r2, test_pred_r2, labels=None, pos_label=1, average='binary')\n",
    "print(f1_train_r2_rf)\n",
    "print(f1_test_r2_rf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### svm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SVC(C=1.0, cache_size=200, class_weight=None, coef0=0.0,\n",
       "    decision_function_shape='ovr', degree=3, gamma='auto_deprecated',\n",
       "    kernel='rbf', max_iter=-1, probability=False, random_state=None,\n",
       "    shrinking=True, tol=0.001, verbose=False)"
      ]
     },
     "execution_count": 203,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Build a SVM Classifier\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "## Create an SVC object and print it to see the default arguments\n",
    "svc = SVC()\n",
    "svc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SVC(C=10, cache_size=200, class_weight=None, coef0=0.0,\n",
       "    decision_function_shape='ovr', degree=3, gamma='auto_deprecated',\n",
       "    kernel='rbf', max_iter=-1, probability=False, random_state=None,\n",
       "    shrinking=True, tol=0.001, verbose=False)"
      ]
     },
     "execution_count": 204,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "svc_c10_rbf = SVC(C=10,kernel='rbf')\n",
    "svc_c10_rbf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Fit the model svc_c10_rbf on the train data (X_train,y_train)\n",
    "svc_c10_rbf.fit(X = tdm_train_r2,y = y_train_r2)\n",
    "\n",
    "#prediction on train data\n",
    "train_pred_r2 = svc_c10_rbf.predict(tdm_train_r2)\n",
    "\n",
    "#predicting on test data\n",
    "test_pred_r2 = svc_c10_rbf.predict(tdm_test_r2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.19714285714285712\n",
      "0.13761467889908255\n"
     ]
    }
   ],
   "source": [
    "f1_train_r2_svc=f1_score( y_train_r2, train_pred_r2, labels=None, pos_label=1, average='binary')\n",
    "f1_test_r2_svc=f1_score( y_test_r2, test_pred_r2, labels=None, pos_label=1, average='binary')\n",
    "print(f1_train_r2_svc)\n",
    "print(f1_test_r2_svc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Grid search on svc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Use Grid Search for parameter tuning\n",
    "\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "svc_grid = SVC()\n",
    " \n",
    "\n",
    "param_grid = {\n",
    "\n",
    "'C': [0.001, 0.01, 0.1, 1, 10],\n",
    "'gamma': [0.001, 0.01, 0.1, 1], \n",
    "'kernel':['linear', 'poly', 'rbf', 'sigmoid']}\n",
    "\n",
    " \n",
    "svc_cv_grid = GridSearchCV(estimator = svc_grid, param_grid = param_grid, cv = 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Fit the grid search model\n",
    "svc_cv_grid.fit(X = tdm_train_r1, y = y_train_r1)\n",
    "\n",
    "train_pred_r1 = svc_cv_grid.predict(tdm_train_r1)\n",
    "\n",
    "test_pred_r1 = svc_cv_grid.predict(tdm_test_r1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8093333333333333 {'C': 10, 'gamma': 0.01, 'kernel': 'rbf'}\n"
     ]
    }
   ],
   "source": [
    "## Print best score and parameters\n",
    "print(svc_cv_grid.best_score_,svc_cv_grid.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "metadata": {},
   "outputs": [],
   "source": [
    "svc_clf_grid = SVC(C=10, gamma=0.01, kernel= 'rbf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Fit the grid search model\n",
    "svc_clf_grid.fit(X = tdm_train_r2, y = y_train_r2)\n",
    "\n",
    "train_pred_r2 = svc_clf_grid.predict(tdm_train_r2)\n",
    "\n",
    "test_pred_r2 = svc_clf_grid.predict(tdm_test_r2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8514492753623188\n",
      "0.608695652173913\n"
     ]
    }
   ],
   "source": [
    "f1_train_r2_svc=f1_score( y_train_r2, train_pred_r2, labels=None, pos_label=1, average='binary')\n",
    "f1_test_r2_svc=f1_score( y_test_r2, test_pred_r2, labels=None, pos_label=1, average='binary')\n",
    "print(f1_train_r2_svc)\n",
    "print(f1_test_r2_svc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ## Fit the grid search model\n",
    "# svc_cv_grid.fit(X = tfidf_train_r1, y = y_train_r1)\n",
    "\n",
    "# train_pred_r1_tf = svc_cv_grid.predict(tfidf_train_r1)\n",
    "\n",
    "# test_pred_r1_tf = svc_cv_grid.predict(tfidf_test_r1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8653500897666068\n",
      "0.6257668711656441\n"
     ]
    }
   ],
   "source": [
    "f1_train_r1_svc=f1_score( y_train_r1, train_pred_r1, labels=None, pos_label=1, average='binary')\n",
    "f1_test_r1_svc=f1_score( y_test_r1, test_pred_r1, labels=None, pos_label=1, average='binary')\n",
    "print(f1_train_r1_svc)\n",
    "print(f1_test_r1_svc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8257777777777778 {'C': 10, 'gamma': 0.1, 'kernel': 'rbf'}\n"
     ]
    }
   ],
   "source": [
    "# ## Print best score and parameters\n",
    "# print(svc_cv_grid.best_score_,svc_cv_grid.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "metadata": {},
   "outputs": [],
   "source": [
    "svc_clf_grid = SVC(C=10, gamma=0.1, kernel= 'rbf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Fit the grid search model\n",
    "svc_clf_grid.fit(X = tfidf_train_r2, y = y_train_r2)\n",
    "\n",
    "train_pred_r2_svc = svc_clf_grid.predict(tfidf_train_r2)\n",
    "\n",
    "test_pred_r2_svc = svc_clf_grid.predict(tfidf_test_r2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9952\n",
      "0.6904109589041095\n"
     ]
    }
   ],
   "source": [
    "f1_train_r2_svc=f1_score( y_train_r2, train_pred_r2_svc, labels=None, pos_label=1, average='binary')\n",
    "f1_test_r2_svc=f1_score( y_test_r2, test_pred_r2_svc, labels=None, pos_label=1, average='binary')\n",
    "print(f1_train_r2_svc)\n",
    "print(f1_test_r2_svc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### review processed 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train_r3, X_test_r3, y_train_r3, y_test_r3 = train_test_split(train_text_dt['review_processed_3'],train_text_dt['sentiment'],test_size=0.25,random_state=123)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2250\n",
      "750\n"
     ]
    }
   ],
   "source": [
    "print(len(X_train_r3))\n",
    "print(len(X_test_r3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "cv = CountVectorizer(stop_words=\"english\",strip_accents=\"unicode\",decode_error=\"ignore\")\n",
    "tdm_train_r3 = cv.fit_transform(X_train_r3)\n",
    "tdm_test_r3 = cv.transform(X_test_r3)\n",
    "\n",
    "##########################################################################################\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "tfidf_vectorizer = TfidfVectorizer(ngram_range=(1,2))\n",
    "tfidf_train_r3 = tfidf_vectorizer.fit_transform(X_train_r3)\n",
    "tfidf_test_r3 = tfidf_vectorizer.transform(X_test_r3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "#training the model\n",
    "logreg = LogisticRegression()\n",
    "lr_clf = logreg.fit(tdm_train_r3,y_train_r3) #or mat which is in dense format can also be used\n",
    "\n",
    "#prediction on train data\n",
    "train_pred_r3 = lr_clf.predict(tdm_train_r3)\n",
    "\n",
    "#predicting on test data\n",
    "test_pred_r3 = lr_clf.predict(tdm_test_r3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train cfm : \n",
      " [[1610   16]\n",
      " [ 105  519]]\n",
      "train cfm : \n",
      " [[511  40]\n",
      " [ 87 112]]\n"
     ]
    }
   ],
   "source": [
    "print(\"train cfm :\",\"\\n\", confusion_matrix(y_train_r3,train_pred_r3))\n",
    "print(\"train cfm :\",\"\\n\", confusion_matrix(y_test_r3,test_pred_r3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8955996548748921\n",
      "0.6381766381766382\n"
     ]
    }
   ],
   "source": [
    "f1_train_r3_log=f1_score( y_train_r3, train_pred_r3, labels=None, pos_label=1, average='binary')\n",
    "f1_test_r3_log=f1_score( y_test_r3, test_pred_r3, labels=None, pos_label=1, average='binary')\n",
    "print(f1_train_r3_log)\n",
    "print(f1_test_r3_log)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### tfidf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train_r3, X_test_r3, y_train_r3, y_test_r3 = train_test_split(train_text_dt['review_processed_3'],train_text_dt['sentiment'],test_size=0.25,random_state=123)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2250\n",
      "750\n"
     ]
    }
   ],
   "source": [
    "print(len(X_train_r3))\n",
    "print(len(X_test_r3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "cv = CountVectorizer(stop_words=\"english\",strip_accents=\"unicode\",decode_error=\"ignore\")\n",
    "tdm_train_r3 = cv.fit_transform(X_train_r3)\n",
    "tdm_test_r3 = cv.transform(X_test_r3)\n",
    "\n",
    "##########################################################################################\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "tfidf_vectorizer = TfidfVectorizer(ngram_range=(1,2))\n",
    "tfidf_train_r3 = tfidf_vectorizer.fit_transform(X_train_r3)\n",
    "tfidf_test_r3 = tfidf_vectorizer.transform(X_test_r3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "#training the model\n",
    "logreg = LogisticRegression()\n",
    "lr_clf = logreg.fit(tfidf_train_r3,y_train_r3) #or mat which is in dense format can also be used\n",
    "\n",
    "#prediction on train data\n",
    "train_pred_r3 = lr_clf.predict(tfidf_train_r3)\n",
    "\n",
    "#predicting on test data\n",
    "test_pred_r3 = lr_clf.predict(tfidf_test_r3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train cfm : \n",
      " [[1622    4]\n",
      " [ 259  365]]\n",
      "train cfm : \n",
      " [[537  14]\n",
      " [132  67]]\n"
     ]
    }
   ],
   "source": [
    "print(\"train cfm :\",\"\\n\", confusion_matrix(y_train_r3,train_pred_r3))\n",
    "print(\"train cfm :\",\"\\n\", confusion_matrix(y_test_r3,test_pred_r3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7351460221550856\n",
      "0.47857142857142865\n"
     ]
    }
   ],
   "source": [
    "f1_train_r3_log=f1_score( y_train_r3, train_pred_r3, labels=None, pos_label=1, average='binary')\n",
    "f1_test_r3_log=f1_score( y_test_r3, test_pred_r3, labels=None, pos_label=1, average='binary')\n",
    "print(f1_train_r3_log)\n",
    "print(f1_test_r3_log)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### random forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [],
   "source": [
    "#build a random forest classifiers\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "rf = RandomForestClassifier()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_clf = rf.fit(tdm_train_r3,y_train_r3)\n",
    "#prediction on train data\n",
    "train_pred_r3 = rf_clf.predict(tdm_train_r3)\n",
    "\n",
    "#predicting on test data\n",
    "test_pred_r3 = rf_clf.predict(tdm_test_r3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9713349713349713\n",
      "0.47741935483870973\n"
     ]
    }
   ],
   "source": [
    "f1_train_r3_rf=f1_score( y_train_r3, train_pred_r3, labels=None, pos_label=1, average='binary')\n",
    "f1_test_r3_rf=f1_score( y_test_r3, test_pred_r3, labels=None, pos_label=1, average='binary')\n",
    "print(f1_train_r3_rf)\n",
    "print(f1_test_r3_rf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### svm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SVC(C=1.0, cache_size=200, class_weight=None, coef0=0.0,\n",
       "    decision_function_shape='ovr', degree=3, gamma='auto_deprecated',\n",
       "    kernel='rbf', max_iter=-1, probability=False, random_state=None,\n",
       "    shrinking=True, tol=0.001, verbose=False)"
      ]
     },
     "execution_count": 199,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Build a SVM Classifier\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "## Create an SVC object and print it to see the default arguments\n",
    "svc = SVC()\n",
    "svc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SVC(C=10, cache_size=200, class_weight=None, coef0=0.0,\n",
       "    decision_function_shape='ovr', degree=3, gamma='auto_deprecated',\n",
       "    kernel='rbf', max_iter=-1, probability=False, random_state=None,\n",
       "    shrinking=True, tol=0.001, verbose=False)"
      ]
     },
     "execution_count": 200,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "svc_c10_rbf = SVC(C=10,kernel='rbf')\n",
    "svc_c10_rbf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Fit the model svc_c10_rbf on the train data (X_train,y_train)\n",
    "svc_c10_rbf.fit(X = tdm_train_r3,y = y_train_r3)\n",
    "\n",
    "#prediction on train data\n",
    "train_pred_r3 = svc_c10_rbf.predict(tdm_train_r3)\n",
    "\n",
    "#predicting on test data\n",
    "test_pred_r3 = svc_c10_rbf.predict(tdm_test_r3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.16593886462882096\n",
      "0.12962962962962962\n"
     ]
    }
   ],
   "source": [
    "f1_train_r3_svc=f1_score( y_train_r3, train_pred_r3, labels=None, pos_label=1, average='binary')\n",
    "f1_test_r3_svc=f1_score( y_test_r3, test_pred_r3, labels=None, pos_label=1, average='binary')\n",
    "print(f1_train_r3_svc)\n",
    "print(f1_test_r3_svc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Grid search on svc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Use Grid Search for parameter tuning\n",
    "\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "svc_grid = SVC()\n",
    " \n",
    "\n",
    "param_grid = {\n",
    "\n",
    "'C': [0.001, 0.01, 0.1, 1, 10],\n",
    "'gamma': [0.001, 0.01, 0.1, 1], \n",
    "'kernel':['linear', 'poly', 'rbf', 'sigmoid']}\n",
    "\n",
    " \n",
    "svc_cv_grid = GridSearchCV(estimator = svc_grid, param_grid = param_grid, cv = 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ## Fit the grid search model\n",
    "# svc_cv_grid.fit(X = tdm_train_r3, y = y_train_r3)\n",
    "\n",
    "# train_pred_r3 = svc_cv_grid.predict(tdm_train_r3)\n",
    "\n",
    "# test_pred_r3 = svc_cv_grid.predict(tdm_test_r3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8093333333333333 {'C': 10, 'gamma': 0.01, 'kernel': 'rbf'}\n"
     ]
    }
   ],
   "source": [
    "# ## Print best score and parameters\n",
    "# print(svc_cv_grid.best_score_,svc_cv_grid.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "metadata": {},
   "outputs": [],
   "source": [
    "svc_clf_grid = SVC(C=10, gamma=0.01, kernel= 'rbf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Fit the grid search model\n",
    "svc_clf_grid.fit(X = tdm_train_r3, y = y_train_r3)\n",
    "\n",
    "train_pred_r3 = svc_clf_grid.predict(tdm_train_r3)\n",
    "\n",
    "test_pred_r3 = svc_clf_grid.predict(tdm_test_r3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 241,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.875886524822695\n",
      "0.6312684365781711\n"
     ]
    }
   ],
   "source": [
    "f1_train_r3_svc=f1_score( y_train_r3, train_pred_r3, labels=None, pos_label=1, average='binary')\n",
    "f1_test_r3_svc=f1_score( y_test_r3, test_pred_r3, labels=None, pos_label=1, average='binary')\n",
    "print(f1_train_r3_svc)\n",
    "print(f1_test_r3_svc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ## Fit the grid search model\n",
    "# svc_cv_grid.fit(X = tfidf_train_r1, y = y_train_r1)\n",
    "\n",
    "# train_pred_r1_tf = svc_cv_grid.predict(tfidf_train_r1)\n",
    "\n",
    "# test_pred_r1_tf = svc_cv_grid.predict(tfidf_test_r1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8653500897666068\n",
      "0.6257668711656441\n"
     ]
    }
   ],
   "source": [
    "# f1_train_r1_svc=f1_score( y_train_r1, train_pred_r1, labels=None, pos_label=1, average='binary')\n",
    "# f1_test_r1_svc=f1_score( y_test_r1, test_pred_r1, labels=None, pos_label=1, average='binary')\n",
    "# print(f1_train_r1_svc)\n",
    "# print(f1_test_r1_svc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8257777777777778 {'C': 10, 'gamma': 0.1, 'kernel': 'rbf'}\n"
     ]
    }
   ],
   "source": [
    "# ## Print best score and parameters\n",
    "# print(svc_cv_grid.best_score_,svc_cv_grid.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 263,
   "metadata": {},
   "outputs": [],
   "source": [
    "svc_clf_grid = SVC(C=8, gamma=0.1, kernel= 'rbf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 264,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Fit the grid search model\n",
    "svc_clf_grid.fit(X = tfidf_train_r3, y = y_train_r3)\n",
    "\n",
    "train_pred_r3_svc = svc_clf_grid.predict(tfidf_train_r3)\n",
    "\n",
    "test_pred_r3_svc = svc_clf_grid.predict(tfidf_test_r3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 265,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9952\n",
      "0.7379679144385026\n"
     ]
    }
   ],
   "source": [
    "f1_train_r3_svc=f1_score( y_train_r3, train_pred_r3_svc, labels=None, pos_label=1, average='binary')\n",
    "f1_test_r3_svc=f1_score( y_test_r3, test_pred_r3_svc, labels=None, pos_label=1, average='binary')\n",
    "print(f1_train_r3_svc)\n",
    "print(f1_test_r3_svc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### review"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train_r, X_test_r, y_train_r, y_test_r = train_test_split(train_text_dt['review'],train_text_dt['sentiment'],test_size=0.25,random_state=123)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2250\n",
      "750\n"
     ]
    }
   ],
   "source": [
    "print(len(X_train_r))\n",
    "print(len(X_test_r))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "cv = CountVectorizer(stop_words=\"english\",strip_accents=\"unicode\",decode_error=\"ignore\")\n",
    "tdm_train_r = cv.fit_transform(X_train_r)\n",
    "tdm_test_r = cv.transform(X_test_r)\n",
    "\n",
    "##########################################################################################\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "tfidf_vectorizer = TfidfVectorizer(ngram_range=(1,2))\n",
    "tfidf_train_r = tfidf_vectorizer.fit_transform(X_train_r)\n",
    "tfidf_test_r = tfidf_vectorizer.transform(X_test_r)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "#training the model\n",
    "logreg = LogisticRegression()\n",
    "lr_clf = logreg.fit(tdm_train_r,y_train_r) #or mat which is in dense format can also be used\n",
    "\n",
    "#prediction on train data\n",
    "train_pred_r = lr_clf.predict(tdm_train_r)\n",
    "\n",
    "#predicting on test data\n",
    "test_pred_r = lr_clf.predict(tdm_test_r)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train cfm : \n",
      " [[1610   16]\n",
      " [ 105  519]]\n",
      "train cfm : \n",
      " [[511  40]\n",
      " [ 87 112]]\n"
     ]
    }
   ],
   "source": [
    "print(\"train cfm :\",\"\\n\", confusion_matrix(y_train_r,train_pred_r))\n",
    "print(\"train cfm :\",\"\\n\", confusion_matrix(y_test_r,test_pred_r))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8955996548748921\n",
      "0.6381766381766382\n"
     ]
    }
   ],
   "source": [
    "f1_train_r_log=f1_score( y_train_r, train_pred_r, labels=None, pos_label=1, average='binary')\n",
    "f1_test_r_log=f1_score( y_test_r, test_pred_r, labels=None, pos_label=1, average='binary')\n",
    "print(f1_train_r_log)\n",
    "print(f1_test_r_log)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### tfidf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train_r, X_test_r, y_train_r, y_test_r = train_test_split(train_text_dt['review'],train_text_dt['sentiment'],test_size=0.25,random_state=123)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2250\n",
      "750\n"
     ]
    }
   ],
   "source": [
    "print(len(X_train_r))\n",
    "print(len(X_test_r))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "cv = CountVectorizer(stop_words=\"english\",strip_accents=\"unicode\",decode_error=\"ignore\")\n",
    "tdm_train_r = cv.fit_transform(X_train_r)\n",
    "tdm_test_r = cv.transform(X_test_r)\n",
    "\n",
    "##########################################################################################\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "tfidf_vectorizer = TfidfVectorizer(ngram_range=(1,2))\n",
    "tfidf_train_r = tfidf_vectorizer.fit_transform(X_train_r)\n",
    "tfidf_test_r = tfidf_vectorizer.transform(X_test_r)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "#training the model\n",
    "logreg = LogisticRegression()\n",
    "lr_clf = logreg.fit(tfidf_train_r,y_train_r) #or mat which is in dense format can also be used\n",
    "\n",
    "#prediction on train data\n",
    "train_pred_r = lr_clf.predict(tfidf_train_r)\n",
    "\n",
    "#predicting on test data\n",
    "test_pred_r = lr_clf.predict(tfidf_test_r)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train cfm : \n",
      " [[1622    4]\n",
      " [ 259  365]]\n",
      "train cfm : \n",
      " [[537  14]\n",
      " [132  67]]\n"
     ]
    }
   ],
   "source": [
    "print(\"train cfm :\",\"\\n\", confusion_matrix(y_train_r,train_pred_r))\n",
    "print(\"train cfm :\",\"\\n\", confusion_matrix(y_test_r,test_pred_r))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7351460221550856\n",
      "0.47857142857142865\n"
     ]
    }
   ],
   "source": [
    "f1_train_r_log=f1_score( y_train_r, train_pred_r, labels=None, pos_label=1, average='binary')\n",
    "f1_test_r_log=f1_score( y_test_r, test_pred_r, labels=None, pos_label=1, average='binary')\n",
    "print(f1_train_r_log)\n",
    "print(f1_test_r_log)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### random forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [],
   "source": [
    "#build a random forest classifiers\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "rf = RandomForestClassifier()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_clf = rf.fit(tdm_train_r,y_train_r)\n",
    "#prediction on train data\n",
    "train_pred_r = rf_clf.predict(tdm_train_r)\n",
    "\n",
    "#predicting on test data\n",
    "test_pred_r = rf_clf.predict(tdm_test_r)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9617940199335548\n",
      "0.47297297297297297\n"
     ]
    }
   ],
   "source": [
    "f1_train_r_rf=f1_score( y_train_r, train_pred_r, labels=None, pos_label=1, average='binary')\n",
    "f1_test_r_rf=f1_score( y_test_r, test_pred_r, labels=None, pos_label=1, average='binary')\n",
    "print(f1_train_r_rf)\n",
    "print(f1_test_r_rf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### svm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SVC(C=1.0, cache_size=200, class_weight=None, coef0=0.0,\n",
       "    decision_function_shape='ovr', degree=3, gamma='auto_deprecated',\n",
       "    kernel='rbf', max_iter=-1, probability=False, random_state=None,\n",
       "    shrinking=True, tol=0.001, verbose=False)"
      ]
     },
     "execution_count": 195,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Build a SVM Classifier\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "## Create an SVC object and print it to see the default arguments\n",
    "svc = SVC()\n",
    "svc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SVC(C=10, cache_size=200, class_weight=None, coef0=0.0,\n",
       "    decision_function_shape='ovr', degree=3, gamma='auto_deprecated',\n",
       "    kernel='rbf', max_iter=-1, probability=False, random_state=None,\n",
       "    shrinking=True, tol=0.001, verbose=False)"
      ]
     },
     "execution_count": 196,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "svc_c10_rbf = SVC(C=10,kernel='rbf')\n",
    "svc_c10_rbf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Fit the model svc_c10_rbf on the train data (X_train,y_train)\n",
    "svc_c10_rbf.fit(X = tdm_train_r,y = y_train_r)\n",
    "\n",
    "#prediction on train data\n",
    "train_pred_r = svc_c10_rbf.predict(tdm_train_r)\n",
    "\n",
    "#predicting on test data\n",
    "test_pred_r = svc_c10_rbf.predict(tdm_test_r)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.16593886462882096\n",
      "0.12962962962962962\n"
     ]
    }
   ],
   "source": [
    "f1_train_r_svc=f1_score( y_train_r, train_pred_r, labels=None, pos_label=1, average='binary')\n",
    "f1_test_r_svc=f1_score( y_test_r, test_pred_r, labels=None, pos_label=1, average='binary')\n",
    "print(f1_train_r_svc)\n",
    "print(f1_test_r_svc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
