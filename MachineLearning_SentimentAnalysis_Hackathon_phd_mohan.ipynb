{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# models built are:-\n",
    "  #### preprocessed data    &    raw data:\n",
    "        count vectorizer  & tfidf vectorizer\n",
    "          1. Logistic regression\n",
    "          2. Random forest\n",
    "          3. Support vector machine\n",
    "          4. Support vector machine with grid search\n",
    "          5. AdaBoost\n",
    "          6. AdaBoost with grid search\n",
    "          7. GradientBoost classifier\n",
    "          8. Xgboost classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import urllib.request as url\n",
    "from bs4 import BeautifulSoup as bs\n",
    "import re\n",
    "import requests\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import random\n",
    "random.seed(123)\n",
    "\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "\n",
    "import os\n",
    "import random\n",
    "import string\n",
    "import datetime as dt\n",
    "\n",
    "# import warnings\n",
    "# warnings.filterwarnings('ignore','RuntimeWarning')\n",
    "\n",
    "import nltk\n",
    "import re\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.classify.scikitlearn import SklearnClassifier\n",
    "from nltk.tokenize import sent_tokenize, word_tokenize\n",
    "from nltk.collocations import BigramCollocationFinder, TrigramCollocationFinder\n",
    "from wordcloud import WordCloud\n",
    "\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from nltk.corpus import movie_reviews\n",
    "from nltk.classify.scikitlearn import SklearnClassifier\n",
    "from nltk.tokenize import word_tokenize\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.metrics import confusion_matrix,accuracy_score,recall_score,precision_score\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "from sklearn.model_selection import train_test_split\n",
    "import nltk\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#reading the file into the notebook\n",
    "import pickle\n",
    "filename = 'f1.csv'\n",
    "infile = open(filename,'rb')\n",
    "train_preprocessed = pickle.load(infile)\n",
    "infile.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3000, 27)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_preprocessed.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['review', 'displayName', 'displayImageUrl', 'isVerified',\n",
       "       'isSuperReviewer', 'hasSpoilers', 'hasProfanity', 'createDate',\n",
       "       'updateDate', 'score', 'timeFromCreation', 'user.realm',\n",
       "       'user.displayName', 'sentiment', 'Create_day', 'create_time',\n",
       "       'update_day', 'update_time', 'review_update_date', 'review_processed_1',\n",
       "       'review_processed_2', 'review_processed_3', 'polarity', 'review_len',\n",
       "       'word_count', 'review_len_cat', 'word_count_cat'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_preprocessed.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_preprocessed = train_preprocessed.drop(labels=['displayName', 'displayImageUrl', 'isVerified',\n",
    "       'isSuperReviewer', 'hasSpoilers', 'hasProfanity', 'createDate',\n",
    "       'updateDate', 'score', 'timeFromCreation', 'user.realm',\n",
    "       'user.displayName', 'Create_day', 'create_time',\n",
    "       'update_day', 'update_time', 'review_update_date','review_processed_3',\n",
    "       'review_processed_2'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    2177\n",
       "0     823\n",
       "Name: sentiment, dtype: int64"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_preprocessed.sentiment.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review</th>\n",
       "      <th>sentiment</th>\n",
       "      <th>review_processed_1</th>\n",
       "      <th>polarity</th>\n",
       "      <th>review_len</th>\n",
       "      <th>word_count</th>\n",
       "      <th>review_len_cat</th>\n",
       "      <th>word_count_cat</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2702</th>\n",
       "      <td>It was good but left a lot of parts out from o...</td>\n",
       "      <td>1</td>\n",
       "      <td>good left part original movie</td>\n",
       "      <td>0.358333</td>\n",
       "      <td>59</td>\n",
       "      <td>13</td>\n",
       "      <td>lessthan150</td>\n",
       "      <td>10-30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2033</th>\n",
       "      <td>It was awesome all the way thru...just didn't ...</td>\n",
       "      <td>1</td>\n",
       "      <td>awesome thru like missed part hyena afraid muf...</td>\n",
       "      <td>-0.116667</td>\n",
       "      <td>123</td>\n",
       "      <td>22</td>\n",
       "      <td>lessthan150</td>\n",
       "      <td>10-30</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 review  sentiment  \\\n",
       "2702  It was good but left a lot of parts out from o...          1   \n",
       "2033  It was awesome all the way thru...just didn't ...          1   \n",
       "\n",
       "                                     review_processed_1  polarity  review_len  \\\n",
       "2702                      good left part original movie  0.358333          59   \n",
       "2033  awesome thru like missed part hyena afraid muf... -0.116667         123   \n",
       "\n",
       "      word_count review_len_cat word_count_cat  \n",
       "2702          13    lessthan150          10-30  \n",
       "2033          22    lessthan150          10-30  "
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_preprocessed.sample(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_preprocessed = train_preprocessed.drop(labels=['polarity', 'review_len', 'word_count','review_len_cat','word_count_cat'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_preprocessed['review_processed_1'] = train_preprocessed['review_processed_1'].apply(lambda x:' '.join(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_preprocessed['sentiment'] = train_preprocessed['sentiment'].replace({0:1, 1:0})\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Review_processed_1\n",
    "    this is preprocessed review"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train_r1, X_test_r1, y_train_r1, y_test_r1 = train_test_split(train_preprocessed['review_processed_1'],train_preprocessed['sentiment'],test_size=0.20,random_state=123)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2400\n",
      "600\n"
     ]
    }
   ],
   "source": [
    "print(len(X_train_r1))\n",
    "print(len(X_test_r1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## initializing counntervecorize and tfidf  vectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "cv = CountVectorizer(stop_words=\"english\",strip_accents=\"unicode\",decode_error=\"ignore\")\n",
    "tdm_train_r1 = cv.fit_transform(X_train_r1)\n",
    "tdm_test_r1 = cv.transform(X_test_r1)\n",
    "\n",
    "# ##########################################################################################\n",
    "\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "tfidf_vectorizer = TfidfVectorizer(ngram_range=(1,2))\n",
    "tfidf_train_r1 = tfidf_vectorizer.fit_transform(X_train_r1)\n",
    "tfidf_test_r1 = tfidf_vectorizer.transform(X_test_r1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## logistic on preprocessed review count vectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8733766233766234\n",
      "0.640926640926641\n"
     ]
    }
   ],
   "source": [
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "#training the model\n",
    "logreg = LogisticRegression()\n",
    "lr_clf = logreg.fit(tdm_train_r1,y_train_r1) #or mat which is in dense format can also be used\n",
    "\n",
    "#prediction on train data\n",
    "train_pred_r1 = lr_clf.predict(tdm_train_r1)\n",
    "\n",
    "#predicting on test data\n",
    "test_pred_r1 = lr_clf.predict(tdm_test_r1)\n",
    "\n",
    "#f1-score on train and test data\n",
    "f1_train_r1_log=f1_score( y_train_r1, train_pred_r1, labels=None, pos_label=1, average='binary')\n",
    "f1_test_r1_log=f1_score( y_test_r1, test_pred_r1, labels=None, pos_label=1, average='binary')\n",
    "print(f1_train_r1_log)\n",
    "print(f1_test_r1_log)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### tfidf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "tfidf_vectorizer = TfidfVectorizer(ngram_range=(1,2))\n",
    "tfidf_train_r1 = tfidf_vectorizer.fit_transform(X_train_r1)\n",
    "tfidf_test_r1 = tfidf_vectorizer.transform(X_test_r1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## logistic on preprocessed review tfidf vectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7313854853911405\n",
      "0.509090909090909\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "#training the model\n",
    "logreg = LogisticRegression()\n",
    "lr_clf = logreg.fit(tfidf_train_r1,y_train_r1) #or mat which is in dense format can also be used\n",
    "\n",
    "#prediction on train data\n",
    "train_pred_r1 = lr_clf.predict(tfidf_train_r1)\n",
    "\n",
    "#predicting on test data\n",
    "test_pred_r1 = lr_clf.predict(tfidf_test_r1)\n",
    "\n",
    "#f1-score on train and test data\n",
    "f1_train_r1_log=f1_score( y_train_r1, train_pred_r1, labels=None, pos_label=1, average='binary')\n",
    "f1_test_r1_log=f1_score( y_test_r1, test_pred_r1, labels=None, pos_label=1, average='binary')\n",
    "print(f1_train_r1_log)\n",
    "print(f1_test_r1_log)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random forest on preprocessed review count vectorizer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "#build a random forest classifiers\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "rf = RandomForestClassifier()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9603112840466926\n",
      "0.509090909090909\n"
     ]
    }
   ],
   "source": [
    "rf_clf = rf.fit(tdm_train_r1,y_train_r1)\n",
    "#prediction on train data\n",
    "train_pred_r1 = rf_clf.predict(tdm_train_r1)\n",
    "\n",
    "#predicting on test data\n",
    "test_predr1 = rf_clf.predict(tdm_test_r1)\n",
    "\n",
    "#f1-score on train and test data\n",
    "f1_train_r1_rf=f1_score( y_train_r1, train_pred_r1, labels=None, pos_label=1, average='binary')\n",
    "f1_test_r1_rf=f1_score( y_test_r1, test_pred_r1, labels=None, pos_label=1, average='binary')\n",
    "print(f1_train_r1_rf)\n",
    "print(f1_test_r1_rf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random forest on preprocessed review tfidf vectorizer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9571317225253312\n",
      "0.509090909090909\n"
     ]
    }
   ],
   "source": [
    "rf_clf = rf.fit(tfidf_train_r1,y_train_r1)\n",
    "#prediction on train data\n",
    "train_pred_r1 = rf_clf.predict(tfidf_train_r1)\n",
    "\n",
    "#predicting on test data\n",
    "test_predr1 = rf_clf.predict(tfidf_test_r1)\n",
    "\n",
    "#f1-score on train and test data\n",
    "f1_train_r1_rf=f1_score( y_train_r1, train_pred_r1, labels=None, pos_label=1, average='binary')\n",
    "f1_test_r1_rf=f1_score( y_test_r1, test_pred_r1, labels=None, pos_label=1, average='binary')\n",
    "print(f1_train_r1_rf)\n",
    "print(f1_test_r1_rf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### svm/cv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SVC(C=1.0, cache_size=200, class_weight=None, coef0=0.0,\n",
       "    decision_function_shape='ovr', degree=3, gamma='auto_deprecated',\n",
       "    kernel='rbf', max_iter=-1, probability=False, random_state=None,\n",
       "    shrinking=True, tol=0.001, verbose=False)"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Build a SVM Classifier\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "## Create an SVC object and print it to see the default arguments\n",
    "svc = SVC()\n",
    "svc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## svc on preprocessed review count vectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0029985007496251877\n",
      "0.0\n"
     ]
    }
   ],
   "source": [
    "## Fit the model svc_c10_rbf on the train data (X_train,y_train)\n",
    "svc.fit(X = tdm_train_r1,y = y_train_r1)\n",
    "\n",
    "#prediction on train data\n",
    "train_pred_r1 = svc.predict(tdm_train_r1)\n",
    "\n",
    "#predicting on test data\n",
    "test_pred_r1 = svc.predict(tdm_test_r1)\n",
    "\n",
    "#f1-score on train and test data\n",
    "f1_train_r1_svc=f1_score( y_train_r1, train_pred_r1, labels=None, pos_label=1, average='binary')\n",
    "f1_test_r1_svc=f1_score( y_test_r1, test_pred_r1, labels=None, pos_label=1, average='binary')\n",
    "print(f1_train_r1_svc)\n",
    "print(f1_test_r1_svc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## svc on preprocessed review tfidf vectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0\n",
      "0.0\n"
     ]
    }
   ],
   "source": [
    "## Fit the model svc_c10_rbf on the train data (X_train,y_train)\n",
    "svc.fit(X = tfidf_train_r1,y = y_train_r1)\n",
    "\n",
    "#prediction on train data\n",
    "train_pred_r1 = svc.predict(tfidf_train_r1)\n",
    "\n",
    "#predicting on test data\n",
    "test_pred_r1 = svc.predict(tfidf_test_r1)\n",
    "\n",
    "##f1-score on train and test data\n",
    "f1_train_r1_svc=f1_score( y_train_r1, train_pred_r1, labels=None, pos_label=1, average='binary')\n",
    "f1_test_r1_svc=f1_score( y_test_r1, test_pred_r1, labels=None, pos_label=1, average='binary')\n",
    "print(f1_train_r1_svc)\n",
    "print(f1_test_r1_svc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Grid search on svc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Use Grid Search for parameter tuning\n",
    "\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "svc_grid = SVC()\n",
    " \n",
    "\n",
    "param_grid = {\n",
    "\n",
    "'C': [0.001, 0.01, 0.1, 1, 10],\n",
    "'gamma': [0.001, 0.01, 0.1, 1], \n",
    "'kernel':['linear', 'poly', 'rbf', 'sigmoid']}\n",
    "\n",
    " \n",
    "svc_cv_grid = GridSearchCV(estimator = svc_grid, param_grid = param_grid, cv = 10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## svc-grid on preprocessed review count vectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Fit the grid search model\n",
    "svc_cv_grid.fit(X = tdm_train_r1, y = y_train_r1)\n",
    "\n",
    "train_pred_r1 = svc_cv_grid.predict(tdm_train_r1)\n",
    "\n",
    "test_pred_r1 = svc_cv_grid.predict(tdm_test_r1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8093333333333333 {'C': 10, 'gamma': 0.01, 'kernel': 'rbf'}\n"
     ]
    }
   ],
   "source": [
    "## Print best score and parameters\n",
    "print(svc_cv_grid.best_score_,svc_cv_grid.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "svc_clf_grid = SVC(C=10, gamma=0.01, kernel= 'rbf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Fit the grid search model\n",
    "svc_clf_grid.fit(X = tdm_train_r1, y = y_train_r1)\n",
    "\n",
    "train_pred_r1 = svc_clf_grid.predict(tdm_train_r1)\n",
    "\n",
    "test_pred_r1 = svc_clf_grid.predict(tdm_test_r1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8494077834179357\n",
      "0.6196078431372549\n"
     ]
    }
   ],
   "source": [
    "f1_train_r1_svc=f1_score( y_train_r1, train_pred_r1, labels=None, pos_label=1, average='binary')\n",
    "f1_test_r1_svc=f1_score( y_test_r1, test_pred_r1, labels=None, pos_label=1, average='binary')\n",
    "print(f1_train_r1_svc)\n",
    "print(f1_test_r1_svc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## svc grid on preprocessed review tfidf vectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Fit the grid search model\n",
    "svc_cv_grid.fit(X = tfidf_train_r1, y = y_train_r1)\n",
    "\n",
    "train_pred_r1_tf = svc_cv_grid.predict(tfidf_train_r1)\n",
    "\n",
    "test_pred_r1_tf = svc_cv_grid.predict(tfidf_test_r1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8653500897666068\n",
      "0.6257668711656441\n"
     ]
    }
   ],
   "source": [
    "f1_train_r1_svc=f1_score( y_train_r1, train_pred_r1_tf, labels=None, pos_label=1, average='binary')\n",
    "f1_test_r1_svc=f1_score( y_test_r1, test_pred_r1_tf, labels=None, pos_label=1, average='binary')\n",
    "print(f1_train_r1_svc)\n",
    "print(f1_test_r1_svc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8257777777777778 {'C': 10, 'gamma': 0.1, 'kernel': 'rbf'}\n"
     ]
    }
   ],
   "source": [
    "## Print best score and parameters\n",
    "print(svc_cv_grid.best_score_,svc_cv_grid.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "svc_clf_grid = SVC(C=10, gamma=0.1, kernel= 'rbf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Fit the grid search model\n",
    "svc_clf_grid.fit(X = tfidf_train_r1, y = y_train_r1)\n",
    "\n",
    "train_pred_r1_tf = svc_clf_grid.predict(tfidf_train_r1)\n",
    "\n",
    "test_pred_r1_tf = svc_clf_grid.predict(tfidf_test_r1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 265,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9952\n",
      "0.7379679144385026\n"
     ]
    }
   ],
   "source": [
    "f1_train_r1_svc=f1_score( y_train_r1, train_pred_r1_svc, labels=None, pos_label=1, average='binary')\n",
    "f1_test_r1_svc=f1_score( y_test_r1, test_pred_r1_svc, labels=None, pos_label=1, average='binary')\n",
    "print(f1_train_r1_svc)\n",
    "print(f1_test_r1_svc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## AdaBoost on  preprocessed review - count vectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "AdaBoost_model = AdaBoostClassifier(\n",
    "    DecisionTreeClassifier(max_depth=2),\n",
    "    n_estimators = 600,\n",
    "    learning_rate =1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9939577039274925\n",
      "0.5647840531561462\n"
     ]
    }
   ],
   "source": [
    "AdaBoost_model.fit(tdm_train_r1,y_train_r1)\n",
    "## Predict on test data and store it in the variable y_pred\n",
    "train_pred = AdaBoost_model.predict(tdm_train_r1)\n",
    "test_pred = AdaBoost_model.predict(tdm_test_r1)\n",
    "\n",
    "#f1-score\n",
    "f1_train=f1_score(y_train_r1, train_pred, labels=None, pos_label=1, average='binary', sample_weight=None)\n",
    "f1_test=f1_score(y_test_r1, test_pred, labels=None, pos_label=1, average='binary', sample_weight=None)\n",
    "print(f1_train)\n",
    "print(f1_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## AdaBoost on  preprocessed review - tfidf vectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9985007496251874\n",
      "0.5171102661596958\n"
     ]
    }
   ],
   "source": [
    "AdaBoost_model.fit(tfidf_train_r1,y_train_r1)\n",
    "## Predict on test data and store it in the variable y_pred\n",
    "train_pred = AdaBoost_model.predict(tfidf_train_r1)\n",
    "test_pred = AdaBoost_model.predict(tfidf_test_r1)\n",
    "\n",
    "#f1-score\n",
    "f1_train=f1_score(y_train_r1, train_pred, labels=None, pos_label=1, average='binary', sample_weight=None)\n",
    "f1_test=f1_score(y_test_r1, test_pred, labels=None, pos_label=1, average='binary', sample_weight=None)\n",
    "print(f1_train)\n",
    "print(f1_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## grid search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid_1 = {'n_estimators': [100,150,200],\n",
    "               'learning_rate': [0.1,0.5,0.9]}\n",
    "AdaBoost_model_clf = GridSearchCV(AdaBoostClassifier(\n",
    "            DecisionTreeClassifier(max_depth=2)),param_grid_1,n_jobs=-1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## adaboost grid search on  preprocessed review - count vectorizer "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Number of features of the model must match the input. Model n_features is 23068 and input n_features is 3496 ",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-117-2137e3ee6565>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mAdaBoost_model_clf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtdm_train_r1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0my_train_r1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mtrain_pred\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mAdaBoost_model\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtdm_train_r1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[0mtest_pred\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mAdaBoost_model\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtdm_test_r1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\weight_boosting.py\u001b[0m in \u001b[0;36mpredict\u001b[1;34m(self, X)\u001b[0m\n\u001b[0;32m    615\u001b[0m         \u001b[0mX\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_validate_data\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    616\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 617\u001b[1;33m         \u001b[0mpred\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdecision_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    618\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    619\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mn_classes_\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m2\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\weight_boosting.py\u001b[0m in \u001b[0;36mdecision_function\u001b[1;34m(self, X)\u001b[0m\n\u001b[0;32m    685\u001b[0m             \u001b[1;31m# The weights are all 1. for SAMME.R\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    686\u001b[0m             pred = sum(_samme_proba(estimator, n_classes, X)\n\u001b[1;32m--> 687\u001b[1;33m                        for estimator in self.estimators_)\n\u001b[0m\u001b[0;32m    688\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m  \u001b[1;31m# self.algorithm == \"SAMME\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    689\u001b[0m             pred = sum((estimator.predict(X) == classes).T * w\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\weight_boosting.py\u001b[0m in \u001b[0;36m<genexpr>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m    685\u001b[0m             \u001b[1;31m# The weights are all 1. for SAMME.R\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    686\u001b[0m             pred = sum(_samme_proba(estimator, n_classes, X)\n\u001b[1;32m--> 687\u001b[1;33m                        for estimator in self.estimators_)\n\u001b[0m\u001b[0;32m    688\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m  \u001b[1;31m# self.algorithm == \"SAMME\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    689\u001b[0m             pred = sum((estimator.predict(X) == classes).T * w\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\weight_boosting.py\u001b[0m in \u001b[0;36m_samme_proba\u001b[1;34m(estimator, n_classes, X)\u001b[0m\n\u001b[0;32m    278\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    279\u001b[0m     \"\"\"\n\u001b[1;32m--> 280\u001b[1;33m     \u001b[0mproba\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mestimator\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict_proba\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    281\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    282\u001b[0m     \u001b[1;31m# Displace zero probabilities so the log is defined.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\sklearn\\tree\\tree.py\u001b[0m in \u001b[0;36mpredict_proba\u001b[1;34m(self, X, check_input)\u001b[0m\n\u001b[0;32m    845\u001b[0m         \"\"\"\n\u001b[0;32m    846\u001b[0m         \u001b[0mcheck_is_fitted\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'tree_'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 847\u001b[1;33m         \u001b[0mX\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_validate_X_predict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcheck_input\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    848\u001b[0m         \u001b[0mproba\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtree_\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    849\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\sklearn\\tree\\tree.py\u001b[0m in \u001b[0;36m_validate_X_predict\u001b[1;34m(self, X, check_input)\u001b[0m\n\u001b[0;32m    400\u001b[0m                              \u001b[1;34m\"match the input. Model n_features is %s and \"\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    401\u001b[0m                              \u001b[1;34m\"input n_features is %s \"\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 402\u001b[1;33m                              % (self.n_features_, n_features))\n\u001b[0m\u001b[0;32m    403\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    404\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: Number of features of the model must match the input. Model n_features is 23068 and input n_features is 3496 "
     ]
    }
   ],
   "source": [
    "AdaBoost_model_clf.fit(tdm_train_r1,y_train_r1)\n",
    "train_pred = AdaBoost_model.predict(tdm_train_r1)\n",
    "test_pred = AdaBoost_model.predict(tdm_test_r1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f1_train=f1_score(y_train_r1, train_pred, labels=None, pos_label=1, average='binary', sample_weight=None)\n",
    "f1_test=f1_score(y_test_r1, test_pred, labels=None, pos_label=1, average='binary', sample_weight=None)\n",
    "print(f1_train)\n",
    "print(f1_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7852380952380953 {'learning_rate': 0.1, 'n_estimators': 100}\n"
     ]
    }
   ],
   "source": [
    "print(AdaBoost_model_clf.best_score_,AdaBoost_model_clf.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [],
   "source": [
    "AdaBoost_model=AdaBoostClassifier(\n",
    "    DecisionTreeClassifier(max_depth=2),\n",
    "    n_estimators = 100,\n",
    "    learning_rate =0.1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## adaboost grid search on  preprocessed review - tfidf vectorizer "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [],
   "source": [
    "AdaBoost_model.fit(tfidf_train_r1,y_train_1r)\n",
    "## Predict on test data and store it in the variable y_pred\n",
    "train_pred = AdaBoost_model.predict(tfidf_train_r1)\n",
    "test_pred = AdaBoost_model.predict(tfidf_test_r1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6441860465116279\n",
      "0.4761904761904761\n"
     ]
    }
   ],
   "source": [
    "f1_train=f1_score(y_train_r1, train_pred, labels=None, pos_label=1, average='binary', sample_weight=None)\n",
    "f1_test=f1_score(y_test_r1, test_pred, labels=None, pos_label=1, average='binary', sample_weight=None)\n",
    "print(f1_train)\n",
    "print(f1_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gradient boost on preprocessed review - count vectorizer "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import GradientBoostingClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "GBM_model= GradientBoostingClassifier(n_estimators=50,\n",
    "                                     learning_rate=0.3,\n",
    "                                     subsample=0.8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "GBM_model.fit(tdm_train_r1,y_train_r1)\n",
    "## Predict on test data and store it in the variable y_pred\n",
    "train_pred = GBM_model.predict(tdm_train_r1)\n",
    "test_pred = GBM_model.predict(tdm_test_r1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7156133828996283\n",
      "0.5083333333333334\n"
     ]
    }
   ],
   "source": [
    "f1_train=f1_score(y_train_r, train_pred, labels=None, pos_label=1, average='binary', sample_weight=None)\n",
    "f1_test=f1_score(y_test_r, test_pred, labels=None, pos_label=1, average='binary', sample_weight=None)\n",
    "print(f1_train)\n",
    "print(f1_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  Gradient boost on preprocessed review - tfidf vectorizer  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "GBM_model.fit(tfidf_train_r1,y_train_r1)\n",
    "## Predict on test data and store it in the variable y_pred\n",
    "train_pred = GBM_model.predict(tfidf_train_r1)\n",
    "test_pred = GBM_model.predict(tfidf_test_r1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7833622183708839\n",
      "0.5625\n"
     ]
    }
   ],
   "source": [
    "f1_train=f1_score(y_train_r1, train_pred, labels=None, pos_label=1, average='binary', sample_weight=None)\n",
    "f1_test=f1_score(y_test_r1, test_pred, labels=None, pos_label=1, average='binary', sample_weight=None)\n",
    "print(f1_train)\n",
    "print(f1_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install xgboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "import xgboost as xgb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## xgboost on preprocessed review - count vectorizer "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb_model = xgb.XGBClassifier()\n",
    "xgb_model.fit(tdm_train_r1,y_train_r1)\n",
    "## Predict on test data and store it in the variable y_pred\n",
    "train_pred = xgb_model.predict(tdm_train_r1)\n",
    "test_pred = xgb_model.predict(tdm_test_r1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5519412381951732\n",
      "0.44545454545454544\n"
     ]
    }
   ],
   "source": [
    "f1_train=f1_score(y_train_r1, train_pred, labels=None, pos_label=1, average='binary', sample_weight=None)\n",
    "f1_test=f1_score(y_test_r1, test_pred, labels=None, pos_label=1, average='binary', sample_weight=None)\n",
    "print(f1_train)\n",
    "print(f1_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  xgboost on preprocessed review - tfidf vectorizer "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb_model = xgb.XGBClassifier()\n",
    "xgb_model.fit(tfidf_train_r1,y_train_r1)\n",
    "## Predict on test data and store it in the variable y_pred\n",
    "train_pred = xgb_model.predict(tfidf_train_r1)\n",
    "test_pred = xgb_model.predict(tfidf_test_r1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6062437059415912\n",
      "0.38235294117647056\n"
     ]
    }
   ],
   "source": [
    "f1_train=f1_score(y_train_r1, train_pred, labels=None, pos_label=1, average='binary', sample_weight=None)\n",
    "f1_test=f1_score(y_test_r1, test_pred, labels=None, pos_label=1, average='binary', sample_weight=None)\n",
    "print(f1_train)\n",
    "print(f1_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## review\n",
    "    this raw review data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train_r, X_test_r, y_train_r, y_test_r = train_test_split(train_preprocessed['review'],train_preprocessed['sentiment'],test_size=0.20,random_state=123)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2400\n",
      "600\n"
     ]
    }
   ],
   "source": [
    "print(len(X_train_r))\n",
    "print(len(X_test_r))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "cv = CountVectorizer(stop_words=\"english\",strip_accents=\"unicode\",decode_error=\"ignore\")\n",
    "tdm_train_r = cv.fit_transform(X_train_r)\n",
    "tdm_test_r = cv.transform(X_test_r)\n",
    "\n",
    "##########################################################################################\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "tfidf_vectorizer = TfidfVectorizer(ngram_range=(1,2))\n",
    "tfidf_train_r = tfidf_vectorizer.fit_transform(X_train_r)\n",
    "tfidf_test_r = tfidf_vectorizer.transform(X_test_r)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## logistic on raw review - count vectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8949044585987261\n",
      "0.6544117647058822\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "#training the model\n",
    "logreg = LogisticRegression()\n",
    "lr_clf = logreg.fit(tdm_train_r,y_train_r) #or mat which is in dense format can also be used\n",
    "\n",
    "#prediction on train data\n",
    "train_pred_r = lr_clf.predict(tdm_train_r)\n",
    "\n",
    "#predicting on test data\n",
    "test_pred_r = lr_clf.predict(tdm_test_r)\n",
    "\n",
    "## f1-score\n",
    "f1_train_r_log=f1_score( y_train_r, train_pred_r, labels=None, pos_label=1, average='binary')\n",
    "f1_test_r_log=f1_score( y_test_r, test_pred_r, labels=None, pos_label=1, average='binary')\n",
    "print(f1_train_r_log)\n",
    "print(f1_test_r_log)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### tfidf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "cv = CountVectorizer(stop_words=\"english\",strip_accents=\"unicode\",decode_error=\"ignore\")\n",
    "tdm_train_r = cv.fit_transform(X_train_r)\n",
    "tdm_test_r = cv.transform(X_test_r)\n",
    "\n",
    "##########################################################################################\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "tfidf_vectorizer = TfidfVectorizer(ngram_range=(1,2))\n",
    "tfidf_train_r = tfidf_vectorizer.fit_transform(X_train_r)\n",
    "tfidf_test_r = tfidf_vectorizer.transform(X_test_r)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## logistic on raw review - tfidf vectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.750465549348231\n",
      "0.42790697674418604\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "#training the model\n",
    "logreg = LogisticRegression()\n",
    "lr_clf = logreg.fit(tfidf_train_r,y_train_r) #or mat which is in dense format can also be used\n",
    "\n",
    "#prediction on train data\n",
    "train_pred_r = lr_clf.predict(tfidf_train_r)\n",
    "\n",
    "#predicting on test data\n",
    "test_pred_r = lr_clf.predict(tfidf_test_r)\n",
    "\n",
    "#f1-score\n",
    "f1_train_r_log=f1_score( y_train_r, train_pred_r, labels=None, pos_label=1, average='binary')\n",
    "f1_test_r_log=f1_score( y_test_r, test_pred_r, labels=None, pos_label=1, average='binary')\n",
    "print(f1_train_r_log)\n",
    "print(f1_test_r_log)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### random forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "#build a random forest classifiers\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "rf = RandomForestClassifier()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random forest on  raw review - count vectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_clf = rf.fit(tdm_train_r,y_train_r)\n",
    "#prediction on train data\n",
    "train_pred_r = rf_clf.predict(tdm_train_r)\n",
    "\n",
    "#predicting on test data\n",
    "test_pred_r = rf_clf.predict(tdm_test_r)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9674922600619196\n",
      "0.4173913043478261\n"
     ]
    }
   ],
   "source": [
    "f1_train_r_rf=f1_score( y_train_r, train_pred_r, labels=None, pos_label=1, average='binary')\n",
    "f1_test_r_rf=f1_score( y_test_r, test_pred_r, labels=None, pos_label=1, average='binary')\n",
    "print(f1_train_r_rf)\n",
    "print(f1_test_r_rf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random forest on  raw review - tfidf vectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_clf = rf.fit(tfidf_train_r,y_train_r)\n",
    "#prediction on train data\n",
    "train_pred_r = rf_clf.predict(tfidf_train_r)\n",
    "\n",
    "#predicting on test data\n",
    "test_pred_r = rf_clf.predict(tfidf_test_r)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9642301710730948\n",
      "0.3813953488372093\n"
     ]
    }
   ],
   "source": [
    "f1_train_r_rf=f1_score( y_train_r, train_pred_r, labels=None, pos_label=1, average='binary')\n",
    "f1_test_r_rf=f1_score( y_test_r, test_pred_r, labels=None, pos_label=1, average='binary')\n",
    "print(f1_train_r_rf)\n",
    "print(f1_test_r_rf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### svm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SVC(C=1.0, cache_size=200, class_weight=None, coef0=0.0,\n",
       "    decision_function_shape='ovr', degree=3, gamma='auto_deprecated',\n",
       "    kernel='rbf', max_iter=-1, probability=False, random_state=None,\n",
       "    shrinking=True, tol=0.001, verbose=False)"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Build a SVM Classifier\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "## Create an SVC object and print it to see the default arguments\n",
    "svc = SVC()\n",
    "svc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SVC(C=10, cache_size=200, class_weight=None, coef0=0.0,\n",
       "    decision_function_shape='ovr', degree=3, gamma='auto_deprecated',\n",
       "    kernel='rbf', max_iter=-1, probability=False, random_state=None,\n",
       "    shrinking=True, tol=0.001, verbose=False)"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "svc_c10_rbf = SVC(C=10,kernel='rbf')\n",
    "svc_c10_rbf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## svc on  raw review - count vectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Fit the model svc_c10_rbf on the train data (X_train,y_train)\n",
    "svc_c10_rbf.fit(X = tdm_train_r,y = y_train_r)\n",
    "\n",
    "#prediction on train data\n",
    "train_pred_r = svc_c10_rbf.predict(tdm_train_r)\n",
    "\n",
    "#predicting on test data\n",
    "test_pred_r = svc_c10_rbf.predict(tdm_test_r)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.16916780354706684\n",
      "0.10778443113772455\n"
     ]
    }
   ],
   "source": [
    "f1_train_r_svc=f1_score( y_train_r, train_pred_r, labels=None, pos_label=1, average='binary')\n",
    "f1_test_r_svc=f1_score( y_test_r, test_pred_r, labels=None, pos_label=1, average='binary')\n",
    "print(f1_train_r_svc)\n",
    "print(f1_test_r_svc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## svc on  raw review -  tfidf vectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0\n",
      "0.0\n"
     ]
    }
   ],
   "source": [
    "## Fit the model svc_c10_rbf on the train data (X_train,y_train)\n",
    "svc_c10_rbf.fit(X = tfidf_train_r,y = y_train_r)\n",
    "\n",
    "#prediction on train data\n",
    "train_pred_r = svc_c10_rbf.predict(tfidf_train_r)\n",
    "\n",
    "#predicting on test data\n",
    "test_pred_r = svc_c10_rbf.predict(tfidf_test_r)\n",
    "\n",
    "#f1-score\n",
    "f1_train_r_svc=f1_score( y_train_r, train_pred_r, labels=None, pos_label=1, average='binary')\n",
    "f1_test_r_svc=f1_score( y_test_r, test_pred_r, labels=None, pos_label=1, average='binary')\n",
    "print(f1_train_r_svc)\n",
    "print(f1_test_r_svc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Grid search on svc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Use Grid Search for parameter tuning\n",
    "\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "svc_grid = SVC()\n",
    " \n",
    "\n",
    "param_grid = {\n",
    "\n",
    "'C': [0.001, 0.01, 0.1, 1, 10],\n",
    "'gamma': [0.001, 0.01, 0.1, 1], \n",
    "'kernel':['linear', 'poly', 'rbf', 'sigmoid']}\n",
    "\n",
    " \n",
    "svc_cv_grid = GridSearchCV(estimator = svc_grid, param_grid = param_grid, cv = 10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## svc-grid on  raw review - count vectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Fit the grid search model\n",
    "svc_cv_grid.fit(X = tdm_train_r1, y = y_train_r)\n",
    "\n",
    "train_pred_r = svc_cv_grid.predict(tdm_train_r)\n",
    "\n",
    "test_pred_r = svc_cv_grid.predict(tdm_test_r)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8093333333333333 {'C': 10, 'gamma': 0.01, 'kernel': 'rbf'}\n"
     ]
    }
   ],
   "source": [
    "## Print best score and parameters\n",
    "print(svc_cv_grid.best_score_,svc_cv_grid.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "svc_clf_grid = SVC(C=10, gamma=0.01, kernel= 'rbf')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## svc grid on  raw review - tfidf vectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8751033912324234\n",
      "0.6441947565543071\n"
     ]
    }
   ],
   "source": [
    "## Fit the grid search model\n",
    "svc_clf_grid.fit(X = tdm_train_r, y = y_train_r)\n",
    "\n",
    "train_pred_r = svc_clf_grid.predict(tdm_train_r)\n",
    "\n",
    "test_pred_r = svc_clf_grid.predict(tdm_test_r)\n",
    "\n",
    "#f1-score\n",
    "f1_train_r_svc=f1_score( y_train_r, train_pred_r, labels=None, pos_label=1, average='binary')\n",
    "f1_test_r_svc=f1_score( y_test_r, test_pred_r, labels=None, pos_label=1, average='binary')\n",
    "print(f1_train_r_svc)\n",
    "print(f1_test_r_svc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Fit the grid search model\n",
    "svc_cv_grid.fit(X = tfidf_train_r, y = y_train_r)\n",
    "\n",
    "train_pred_r_tf = svc_cv_grid.predict(tfidf_train_r)\n",
    "\n",
    "test_pred_r_tf = svc_cv_grid.predict(tfidf_test_r)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "f1_train_r_svc=f1_score( y_train_r, train_pred_r_tf, labels=None, pos_label=1, average='binary')\n",
    "f1_test_r_svc=f1_score( y_test_r, test_pred_r_tf, labels=None, pos_label=1, average='binary')\n",
    "print(f1_train_r_svc)\n",
    "print(f1_test_r_svc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8257777777777778 {'C': 10, 'gamma': 0.1, 'kernel': 'rbf'}\n"
     ]
    }
   ],
   "source": [
    "## Print best score and parameters\n",
    "print(svc_cv_grid.best_score_,svc_cv_grid.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "svc_clf_grid = SVC(C=10, gamma=0.1, kernel= 'rbf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9977494373593397\n",
      "0.7297297297297298\n"
     ]
    }
   ],
   "source": [
    "## Fit the grid search model\n",
    "svc_clf_grid.fit(X = tfidf_train_r, y = y_train_r)\n",
    "\n",
    "train_pred_r_tf = svc_clf_grid.predict(tfidf_train_r)\n",
    "\n",
    "test_pred_r_tf = svc_clf_grid.predict(tfidf_test_r)\n",
    "\n",
    "#f1-score\n",
    "f1_train_r_svc=f1_score( y_train_r, train_pred_r_tf, labels=None, pos_label=1, average='binary')\n",
    "f1_test_r_svc=f1_score( y_test_r, test_pred_r_tf, labels=None, pos_label=1, average='binary')\n",
    "print(f1_train_r_svc)\n",
    "print(f1_test_r_svc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "cv = CountVectorizer(stop_words=\"english\",strip_accents=\"unicode\",decode_error=\"ignore\")\n",
    "tdm_train_r = cv.fit_transform(X_train_r)\n",
    "tdm_test_r = cv.transform(X_test_r)\n",
    "\n",
    "##########################################################################################\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "tfidf_vectorizer = TfidfVectorizer(ngram_range=(1,2))\n",
    "tfidf_train_r = tfidf_vectorizer.fit_transform(X_train_r)\n",
    "tfidf_test_r = tfidf_vectorizer.transform(X_test_r)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## AdaBoost on  raw review - count vectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "AdaBoost_model = AdaBoostClassifier(\n",
    "    DecisionTreeClassifier(max_depth=2),\n",
    "    n_estimators = 600,\n",
    "    learning_rate =1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9962377727614748\n",
      "0.5392491467576792\n"
     ]
    }
   ],
   "source": [
    "AdaBoost_model.fit(tdm_train_r,y_train_r)\n",
    "## Predict on test data and store it in the variable y_pred\n",
    "train_pred = AdaBoost_model.predict(tdm_train_r)\n",
    "test_pred = AdaBoost_model.predict(tdm_test_r)\n",
    "\n",
    "#f1-score\n",
    "f1_train=f1_score(y_train_r, train_pred, labels=None, pos_label=1, average='binary', sample_weight=None)\n",
    "f1_test=f1_score(y_test_r, test_pred, labels=None, pos_label=1, average='binary', sample_weight=None)\n",
    "print(f1_train)\n",
    "print(f1_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## AdaBoost on  raw review - tfidf vectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0\n",
      "0.5418060200668896\n"
     ]
    }
   ],
   "source": [
    "AdaBoost_model.fit(tfidf_train_r,y_train_r)\n",
    "## Predict on test data and store it in the variable y_pred\n",
    "train_pred = AdaBoost_model.predict(tfidf_train_r)\n",
    "test_pred = AdaBoost_model.predict(tfidf_test_r)\n",
    "\n",
    "#f1-score\n",
    "f1_train=f1_score(y_train_r, train_pred, labels=None, pos_label=1, average='binary', sample_weight=None)\n",
    "f1_test=f1_score(y_test_r, test_pred, labels=None, pos_label=1, average='binary', sample_weight=None)\n",
    "print(f1_train)\n",
    "print(f1_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## grid search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid_1 = {'n_estimators': [100,150,200],\n",
    "               'learning_rate': [0.1,0.5,0.9]}\n",
    "AdaBoost_model_clf = GridSearchCV(AdaBoostClassifier(\n",
    "            DecisionTreeClassifier(max_depth=2)),param_grid_1,n_jobs=-1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## adaboost grid search on  raw review - count vectorizer "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [],
   "source": [
    "AdaBoost_model_clf.fit(tdm_train,y_train)\n",
    "train_pred = AdaBoost_model.predict(tdm_train)\n",
    "test_pred = AdaBoost_model.predict(tdm_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7713097713097713\n",
      "0.5505050505050505\n"
     ]
    }
   ],
   "source": [
    "f1_train=f1_score(y_train, train_pred, labels=None, pos_label=1, average='binary', sample_weight=None)\n",
    "f1_test=f1_score(y_test, test_pred, labels=None, pos_label=1, average='binary', sample_weight=None)\n",
    "print(f1_train)\n",
    "print(f1_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7852380952380953 {'learning_rate': 0.1, 'n_estimators': 100}\n"
     ]
    }
   ],
   "source": [
    "print(AdaBoost_model_clf.best_score_,AdaBoost_model_clf.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [],
   "source": [
    "AdaBoost_model=AdaBoostClassifier(\n",
    "    DecisionTreeClassifier(max_depth=2),\n",
    "    n_estimators = 100,\n",
    "    learning_rate =0.1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## adaboost grid search on  raw review - tfidf vectorizer "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [],
   "source": [
    "AdaBoost_model.fit(tfidf_train_r,y_train_r)\n",
    "## Predict on test data and store it in the variable y_pred\n",
    "train_pred = AdaBoost_model.predict(tfidf_train_r)\n",
    "test_pred = AdaBoost_model.predict(tfidf_test_r)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6441860465116279\n",
      "0.4761904761904761\n"
     ]
    }
   ],
   "source": [
    "f1_train=f1_score(y_train_r, train_pred, labels=None, pos_label=1, average='binary', sample_weight=None)\n",
    "f1_test=f1_score(y_test_r, test_pred, labels=None, pos_label=1, average='binary', sample_weight=None)\n",
    "print(f1_train)\n",
    "print(f1_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gradient boost on raw review - count vectorizer "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import GradientBoostingClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "GBM_model= GradientBoostingClassifier(n_estimators=50,\n",
    "                                     learning_rate=0.3,\n",
    "                                     subsample=0.8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "GBM_model.fit(tdm_train_r,y_train_r)\n",
    "## Predict on test data and store it in the variable y_pred\n",
    "train_pred = GBM_model.predict(tdm_train_r)\n",
    "test_pred = GBM_model.predict(tdm_test_r)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7355072463768115\n",
      "0.5537190082644629\n"
     ]
    }
   ],
   "source": [
    "f1_train=f1_score(y_train_r, train_pred, labels=None, pos_label=1, average='binary', sample_weight=None)\n",
    "f1_test=f1_score(y_test_r, test_pred, labels=None, pos_label=1, average='binary', sample_weight=None)\n",
    "print(f1_train)\n",
    "print(f1_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  Gradient boost on raw review - tfidf vectorizer  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "GBM_model.fit(tfidf_train_r,y_train_r)\n",
    "## Predict on test data and store it in the variable y_pred\n",
    "train_pred = GBM_model.predict(tfidf_train_r)\n",
    "test_pred = GBM_model.predict(tfidf_test_r)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.846153846153846\n",
      "0.5799256505576208\n"
     ]
    }
   ],
   "source": [
    "f1_train=f1_score(y_train_r, train_pred, labels=None, pos_label=1, average='binary', sample_weight=None)\n",
    "f1_test=f1_score(y_test_r, test_pred, labels=None, pos_label=1, average='binary', sample_weight=None)\n",
    "print(f1_train)\n",
    "print(f1_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install xgboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "import xgboost as xgb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## xgboost on raw review - count vectorizer "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb_model = xgb.XGBClassifier()\n",
    "xgb_model.fit(tdm_train_r,y_train_r)\n",
    "## Predict on test data and store it in the variable y_pred\n",
    "train_pred = xgb_model.predict(tdm_train_r)\n",
    "test_pred = xgb_model.predict(tdm_test_r)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5456475583864119\n",
      "0.49549549549549543\n"
     ]
    }
   ],
   "source": [
    "f1_train=f1_score(y_train_r, train_pred, labels=None, pos_label=1, average='binary', sample_weight=None)\n",
    "f1_test=f1_score(y_test_r, test_pred, labels=None, pos_label=1, average='binary', sample_weight=None)\n",
    "print(f1_train)\n",
    "print(f1_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  xgboost on raw review - tfidf vectorizer "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb_model = xgb.XGBClassifier()\n",
    "xgb_model.fit(tfidf_train_r,y_train_r)\n",
    "## Predict on test data and store it in the variable y_pred\n",
    "train_pred = xgb_model.predict(tfidf_train_r)\n",
    "test_pred = xgb_model.predict(tfidf_test_r)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6779981114258734\n",
      "0.48672566371681414\n"
     ]
    }
   ],
   "source": [
    "f1_train=f1_score(y_train_r, train_pred, labels=None, pos_label=1, average='binary', sample_weight=None)\n",
    "f1_test=f1_score(y_test_r, test_pred, labels=None, pos_label=1, average='binary', sample_weight=None)\n",
    "print(f1_train)\n",
    "print(f1_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
